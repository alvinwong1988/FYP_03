{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alvin/Documents/VTC_CS/VTC Project/Project Final/POC/Violence-Detection/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, LSTM, TimeDistributed, Flatten, Input,GRU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "def build_model(application,model_layer):\n",
    "    # Load the model\n",
    "    base_model = application(weights='imagenet', include_top=False, input_shape=(96,96, 3))\n",
    "\n",
    "    # Make the base model non-trainable\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Define the input shape for our final model\n",
    "    # The shape should be (num_frames, height, width, channels)\n",
    "    # Replace num_frames with the number of frames in our video data\n",
    "    input_shape = (16, 96,96, 3)\n",
    "    model_input = Input(shape=input_shape)\n",
    "\n",
    "    # Add a TimeDistributed wrapper to handle the time dimension in the video data\n",
    "    x = TimeDistributed(base_model)(model_input)\n",
    "\n",
    "    # Flatten the output\n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    # Add an LSTM layer to handle the sequence of features extracted from the frames\n",
    "    x = model_layer(256)(x)\n",
    "\n",
    "    # Add a Dense layer for binary classification\n",
    "    output = Dense(2, activation='softmax')(x)\n",
    "    return Model(inputs=model_input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Features/features_Own96.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m features,labels\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFeatures/features_Own96.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures/labels_Own96.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/VTC_CS/VTC Project/Project Final/POC/Violence-Detection/venv/lib/python3.9/site-packages/numpy/lib/_npyio_impl.py:455\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    456\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Features/features_Own96.npy'"
     ]
    }
   ],
   "source": [
    "features,labels=np.load(\"Features/features_Own96.npy\"),np.load(\"Features/labels_Own96.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size=0.2,\n",
    "                                                                            shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model\n",
    "vgg19_model = build_model(VGG19,LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 10, restore_best_weights = True)\n",
    "\n",
    "# Create ReduceLROnPlateau Callback to reduce overfitting by decreasing learning\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.6,patience=5,min_lr=0.00005,verbose=1)\n",
    " \n",
    "# Compiling the model \n",
    "vgg19_model.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = [\"accuracy\"]) \n",
    " \n",
    "# Fitting the model \n",
    "history = vgg19_model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 8 ,\n",
    "                                             shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `predicted_labels` are the predictions of model on the test set\n",
    "predicted_labels = []\n",
    "batch_size = 8  # Further reduce this value based on GPU's memory\n",
    "for i in range(0, features_test.shape[0], batch_size):\n",
    "    batch_predictions = vgg19_model.predict(features_test[i:i+batch_size], verbose=0)\n",
    "    batch_predictions = np.argmax(batch_predictions, axis=1)\n",
    "    predicted_labels.extend(batch_predictions)\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "true_labels = np.argmax(labels_test, axis=1)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report of VGG19:\")\n",
    "print(classification_report(true_labels, predicted_labels))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_mat = confusion_matrix(true_labels, predicted_labels)\n",
    "# print(\"\\nConfusion Matrix of VGG19:\")\n",
    "# print(conf_mat)\n",
    "\n",
    "# Heatmap for Confusion Matrix\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_mat, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(true_labels, predicted_labels)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve of VGG19')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[6,4])\n",
    "plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
    "plt.plot(history.history['val_loss'], 'blue', linewidth=2.0)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=10)\n",
    "plt.title('Loss Curves of VGG19', fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
